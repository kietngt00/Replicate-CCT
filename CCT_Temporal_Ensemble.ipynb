{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866787a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/root2/CCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3382520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import dataloaders\n",
    "import models\n",
    "import math\n",
    "from utils import Logger\n",
    "from trainer import Trainer\n",
    "import torch.nn.functional as F\n",
    "from utils.losses import abCE_loss, CE_loss, consistency_weight, FocalLoss, softmax_helper, get_alpha\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from utils.metrics import eval_metrics, AverageMeter\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25892b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90676d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./configs/config_temporal.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADERS\n",
    "config['train_supervised']['n_labeled_examples'] = config['n_labeled_examples']\n",
    "supervised_loader = dataloaders.VOC(config['train_supervised'])\n",
    "val_loader = dataloaders.VOC(config['val_loader'])\n",
    "iter_per_epoch = len(supervised_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaed4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def temporal_loss(out1, out2, w, labels, mask_T):\n",
    "    sup_loss = F.cross_entropy(out1, labels, ignore_index=255)\n",
    "    \n",
    "    # out2: (B,C,H,W)\n",
    "    if w == 0:\n",
    "        return sup_loss, sup_loss, torch.tensor(0)\n",
    "    \n",
    "    pseudo_label = F.softmax(out2, dim=1) # (B,C,H,W): compute the probability distribution over C classes\n",
    "    low_confident_mask = torch.amax(pseudo_label, dim=1) < mask_T # (B,H,W) # Get the highest prob, if prob < threshold, ignore that position\n",
    "    pseudo_label = pseudo_label.argmax(dim=1) # (B,H,W) # turn prob distribution into class index\n",
    "    pseudo_label[low_confident_mask] = 255 # Ignore position with low condifent\n",
    "    unsup_loss = F.cross_entropy(out1, pseudo_label, ignore_index=255)\n",
    "    \n",
    "    return sup_loss + w * unsup_loss, sup_loss, w * unsup_loss\n",
    "\n",
    "def ramp_up(epoch, max_epochs, max_val, mult):\n",
    "    if epoch == 0:\n",
    "        return 0.\n",
    "    elif epoch >= max_epochs:\n",
    "        return max_val\n",
    "    return max_val * np.exp(mult * (1. - float(epoch) / max_epochs) ** 2)\n",
    "\n",
    "\n",
    "def weight_schedule(epoch, max_epochs, max_val, mult, n_samples):\n",
    "    return ramp_up(epoch, max_epochs, max_val, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = models.CCT(num_classes=21, conf=config['model'], testing=True)\n",
    "CCT_checkpoint = torch.load('./saved/CCT_wssl/best_model.pth')\n",
    "model = torch.nn.DataParallel(model)\n",
    "try:\n",
    "    model.load_state_dict(CCT_checkpoint['state_dict'], strict=True)\n",
    "except Exception as e:\n",
    "    print(f'Some modules are missing: {e}')\n",
    "    model.load_state_dict(CCT_checkpoint['state_dict'], strict=False)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=2.5e-4, weight_decay=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain, n_classes, H, W = config['n_labeled_examples'], 21, 320, 320\n",
    "losses = []\n",
    "sup_losses = []\n",
    "unsup_losses = []\n",
    "best_loss = 20.\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "alpha = 0.6\n",
    "max_val=30.\n",
    "ramp_up_mult=-5.\n",
    "mask_T = 0.2\n",
    "\n",
    "Z = torch.zeros(ntrain, n_classes, H, W).float().cuda()  # intermediate values\n",
    "z = torch.zeros(ntrain, n_classes, H, W).float().cuda()  # temporal outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d87113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_val_mIoU = 0.735\n",
    "mIoU_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    tbar = tqdm(supervised_loader, ncols=135)\n",
    "    \n",
    "#     w = weight_schedule(epoch, num_epochs, max_val, ramp_up_mult, ntrain)\n",
    "     \n",
    "#     print('unsupervised loss weight : {}'.format(w))\n",
    "\n",
    "#     # turn it into a usable pytorch object\n",
    "#     w = torch.tensor([w], dtype=float, requires_grad=False).cuda()\n",
    "\n",
    "    l = []\n",
    "    supl = []\n",
    "    unsupl = []\n",
    "    \n",
    "    for i, (images, labels) in enumerate(tbar):\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(images)\n",
    "        zcomp = z[i * batch_size: (i + 1) * batch_size].detach()\n",
    "#         zcomp.requires_grad = False\n",
    "        if epoch == 0:\n",
    "            loss, suploss, unsuploss = temporal_loss(out, zcomp, 0, labels, mask_T)\n",
    "        else:\n",
    "            loss, suploss, unsuploss = temporal_loss(out, zcomp, 0.01, labels, mask_T)\n",
    "        \n",
    "        # update temporal ensemble\n",
    "        Z[i * batch_size: (i + 1) * batch_size] = alpha * Z[i * batch_size: (i + 1) * batch_size] + (1. - alpha) * out\n",
    "        z[i * batch_size: (i + 1) * batch_size] = Z[i * batch_size: (i + 1) * batch_size] * (1. / (1. - alpha ** (epoch + 1)))\n",
    "\n",
    "        # save outputs and losses\n",
    "#         outputs[i * batch_size: (i + 1) * batch_size] = out.data.clone()\n",
    "        l.append(loss.item())\n",
    "        supl.append(suploss.item())\n",
    "        unsupl.append(unsuploss.item())\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss\n",
    "        tbar.set_description('Epoch [%d/%d], Step [%d/%d], suploss: %.3f, unsuploss: %.3f' \n",
    "                               %(epoch + 1, num_epochs, i + 1, iter_per_epoch, np.mean(supl), np.mean(unsupl)))\n",
    "\n",
    "    # Eval epoch\n",
    "    model.eval()\n",
    "    total_loss_val = AverageMeter()\n",
    "    total_inter, total_union = 0, 0\n",
    "    total_correct, total_label = 0, 0\n",
    "    mIoU= None\n",
    "    \n",
    "    tbar = tqdm(val_loader, ncols=135)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(tbar):\n",
    "            target, data = target.cuda(), data.cuda()\n",
    "\n",
    "            H, W = target.size(1), target.size(2)\n",
    "            up_sizes = (ceil(H / 8) * 8, ceil(W / 8) * 8)\n",
    "            pad_h, pad_w = up_sizes[0] - data.size(2), up_sizes[1] - data.size(3)\n",
    "            data = F.pad(data, pad=(0, pad_w, 0, pad_h), mode='reflect')\n",
    "            output = model(data)\n",
    "            output = output[:, :, :H, :W]\n",
    "            \n",
    "            loss = F.cross_entropy(output, target, ignore_index=255)\n",
    "            total_loss_val.update(loss.item())\n",
    "            correct, labeled, inter, union = eval_metrics(output, target, 21, 255)\n",
    "            total_inter, total_union = total_inter+inter, total_union+union\n",
    "            total_correct, total_label = total_correct+correct, total_label+labeled\n",
    "            \n",
    "            # PRINT INFO\n",
    "            pixAcc = 1.0 * total_correct / (np.spacing(1) + total_label)\n",
    "            IoU = 1.0 * total_inter / (np.spacing(1) + total_union)\n",
    "            mIoU = IoU.mean()\n",
    "            seg_metrics = {\"Pixel_Accuracy\": np.round(pixAcc, 3), \"Mean_IoU\": np.round(mIoU, 3),\n",
    "                            \"Class_IoU\": dict(zip(range(21), np.round(IoU, 3)))}\n",
    "\n",
    "            tbar.set_description('EVAL ({}) | Loss: {:.3f}, PixelAcc: {:.2f}, Mean IoU: {:.3f} |'.format( epoch,\n",
    "                                            total_loss_val.average, pixAcc, mIoU))\n",
    "        \n",
    "    mIoU_hist.append(mIoU)    \n",
    "    if mIoU > best_val_mIoU:\n",
    "        best_val_mIoU = mIoU\n",
    "        state = {\n",
    "            'CCT_state_dict': model.state_dict(),\n",
    "            'discriminator_state_dict': model_D.state_dict()\n",
    "        }\n",
    "        os.makedirs(f'./saved/Temporal_Ensemble/{best_val_mIoU}')\n",
    "        torch.save(state, f'./saved/Temporal_Ensemble/{best_val_mIoU}/best_model.pth')\n",
    "        print('Save best checkpoint, mIoU: ', mIoU)\n",
    "    \n",
    "    # update temporal ensemble\n",
    "#     Z = alpha * Z + (1. - alpha) * outputs\n",
    "#     z = Z * (1. / (1. - alpha ** (epoch + 1)))\n",
    "\n",
    "    # handle metrics, losses, etc.\n",
    "    eloss = np.mean(l)\n",
    "    losses.append(eloss)\n",
    "    sup_losses.append(np.mean(supl))\n",
    "    unsup_losses.append(np.mean(unsupl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
